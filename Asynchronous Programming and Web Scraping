use tokio::runtime::Runtime;
use tokio::task::{spawn, JoinHandle};
use reqwest::{Client, Url};
use scraper::{Html, Selector};

async fn scrape_website(url: Url) -> String {
    let client = Client::new();
    let response = client.get(url).await.unwrap();

    if response.status().is_success() {
        let html = response.text().await.unwrap();
        let parsed_html = Html::parse_document(&html);

        let selector = Selector::parse(".content").unwrap();
        let content = parsed_html.select(&selector).next().unwrap();

        content.inner_html().to_string()
    } else {
        String::from("Error: Failed to access website!")
    }
}

fn main() {
    let url = Url::parse("https://www.example.com").unwrap();

    let runtime = Runtime::new().unwrap();
    let mut handle: JoinHandle<_> = runtime.spawn(scrape_website(url));

    let result = runtime.block_on(async {
        handle.await.unwrap()
    });

    println!("Scraped text: {}", result);
}
